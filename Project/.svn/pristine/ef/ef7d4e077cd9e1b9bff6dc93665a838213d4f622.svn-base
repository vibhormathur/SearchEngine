package ir.assignments.four;

import java.io.File;
import java.io.IOException;
import java.io.StringReader;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.en.EnglishAnalyzer;
import org.apache.lucene.analysis.miscellaneous.PerFieldAnalyzerWrapper;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
import org.apache.lucene.document.Document;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.queryparser.classic.ParseException;
import org.apache.lucene.queryparser.classic.QueryParser;
import org.apache.lucene.search.BooleanClause.Occur;
import org.apache.lucene.search.BooleanQuery;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.PhraseQuery;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.search.TopDocs;
import org.apache.lucene.search.highlight.Highlighter;
import org.apache.lucene.search.highlight.InvalidTokenOffsetsException;
import org.apache.lucene.search.highlight.QueryScorer;
import org.apache.lucene.search.highlight.SimpleHTMLFormatter;
import org.apache.lucene.search.highlight.TextFragment;
import org.apache.lucene.search.highlight.TokenSources;
import org.apache.lucene.search.highlight.Scorer;
import org.apache.lucene.search.spans.SpanFirstQuery;
import org.apache.lucene.search.spans.SpanNearQuery;
import org.apache.lucene.search.spans.SpanQuery;
import org.apache.lucene.search.spans.SpanTermQuery;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.util.Version;

public class SearchFiles {
	private IndexReader reader;
	private IndexSearcher searcher;
	private Analyzer analyzer;

	public SearchFiles(String indexLocation) throws IOException {
		this.reader = DirectoryReader.open(FSDirectory.open(new File(indexLocation)));
		this.searcher = new IndexSearcher(reader);

		Analyzer regularAnalyzer = new StandardAnalyzer(Version.LUCENE_41);	
		Analyzer stemAnalyzer = new EnglishAnalyzer(Version.LUCENE_41);

		// Use the stem analyzer for some fields, the regular analyzer for the rest
		// Note: Should match mapping used in Indexer.java
		Map<String,Analyzer> analyzerPerField = new HashMap<String,Analyzer>();
		analyzerPerField.put("stemcontent", stemAnalyzer);
		analyzerPerField.put("stemtitle", stemAnalyzer);
		analyzerPerField.put("stemanchortext", stemAnalyzer);

		this.analyzer = new PerFieldAnalyzerWrapper(regularAnalyzer, analyzerPerField);
	}

	public ResultSet search(String queryString, int page, int maxPerPage) {

		// Do search by combining the query among different fields with different boosting weights
		try {
			// Build query
			Query[] queries = new Query[]
					{
					getFieldQuery(queryString, "urldomain", 5.3f),

					getFieldSpanQuery(queryString, "title", 240.5f),
					getFieldSpanQuery(queryString, "stemtitle", 77.7f),
					getFieldNearQuery(queryString, "stemtitle", 1.0f),

					getFieldQuery(queryString, "content", 116.2f),
					getFieldQuery(queryString, "stemcontent", 331.4f),
					getFieldNearQuery(queryString, "stemcontent", 91.0f),

					getFieldQuery(queryString, "contentheaders", 15.3f),
					getFieldQuery(queryString, "importantcontent", 129.9f),

					getFieldQuery(queryString, "anchortext", 17.6f),
					getFieldQuery(queryString, "stemanchortext", 74.6f)
					};

			BooleanQuery finalQuery = new BooleanQuery();
			for (Query query : queries) {
				if (query.getBoost() > 0.0f)
					finalQuery.add(query, Occur.SHOULD);
			}

			return doPagingSearch(finalQuery, page, maxPerPage);
		}
		catch (Exception e) {
			e.printStackTrace();
		}

		return null;
	}

	public ResultSet search(String queryString, int page, int maxPerPage, float[] weightVector) {
		// Used by SearchOptimizer.java to find the best weights for the test queries

		try {
			// Build query
			Query[] queries = new Query[]
					{
					getFieldQuery(queryString, "url", weightVector[0]),
					getFieldQuery(queryString, "urldomain", weightVector[1]),

					getFieldQuery(queryString, "title", weightVector[2]),
					getFieldSpanQuery(queryString, "title", weightVector[3]),
					getFieldQuery(queryString, "stemtitle", weightVector[4]),
					getFieldSpanQuery(queryString, "stemtitle", weightVector[5]),

					getFieldQuery(queryString, "content", weightVector[6]),
					getFieldQuery(queryString, "stemcontent", weightVector[7]),
					getFieldPhraseQuery(queryString, "content", weightVector[8]),

					getFieldQuery(queryString, "contentheaders", weightVector[9]),
					getFieldQuery(queryString, "importantcontent", weightVector[10]),

					getFieldQuery(queryString, "outgoingtext", weightVector[11]),
					getFieldQuery(queryString, "anchortext", weightVector[12]),
					getFieldQuery(queryString, "stemanchortext", weightVector[13]),

					getFieldNearQuery(queryString, "title", weightVector[14]),
					getFieldNearQuery(queryString, "stemtitle", weightVector[15]),
					getFieldNearQuery(queryString, "content", weightVector[16]),
					getFieldNearQuery(queryString, "stemcontent", weightVector[17]),
					getFieldNearQuery(queryString, "contentheaders", weightVector[18]),
					getFieldNearQuery(queryString, "importantcontent", weightVector[19])
					};

			BooleanQuery finalQuery = new BooleanQuery();
			for (Query query : queries) {
				if (query.getBoost() > 0.0f) {
					finalQuery.add(query, Occur.SHOULD);
				}
			}

			return doPagingSearch(finalQuery, page, maxPerPage);
		}
		catch (Exception e) {
			e.printStackTrace();
		}

		return null;
	}

	private Query getFieldQuery(String queryString, String field, float boost) throws ParseException {
		// Build a default query for the field
		QueryParser parser = new QueryParser(Version.LUCENE_41, field, this.analyzer);
		Query query = parser.parse(queryString);
		query.setBoost(boost);
		return query;		
	}

	private Query getFieldSpanQuery(String queryString, String field, float boost) throws ParseException, IOException {
		// Build a query that matches documents were the query string is in the beginning of the field
		// e.g. this can be used to give preference to title's with the query strings near the beginning

		// Split the query string into tokens
		TokenStream tokens = this.analyzer.tokenStream(field, new StringReader(queryString));
		tokens.reset();

		BooleanQuery query = new BooleanQuery();

		// Allow each token to be k terms from the start (starting with 1)
		int k = 1;
		while (tokens.incrementToken()) {
			String word = tokens.getAttribute(CharTermAttribute.class).toString();
			SpanTermQuery spanTermQuery = new SpanTermQuery(new Term(field, word));
			SpanFirstQuery spanFirstQuery = new SpanFirstQuery(spanTermQuery, k);
			k++;

			query.add(spanFirstQuery, Occur.SHOULD);
		}
		query.setBoost(boost);

		return query;		
	}

	private Query getFieldPhraseQuery(String queryString, String field, float boost) throws ParseException, IOException {
		// Build a query that matches the query string as an exact phrase
		TokenStream tokens = this.analyzer.tokenStream(field, new StringReader(queryString));
		tokens.reset();

		PhraseQuery query = new PhraseQuery();
		while (tokens.incrementToken()) {
			String word = tokens.getAttribute(CharTermAttribute.class).toString();
			query.add(new Term(field, word));
		}
		query.setBoost(boost);

		return query;
	}

	private Query getFieldNearQuery(String queryString, String field, float boost) throws ParseException, IOException {
		// Build a query that matches the query terms close to each other
		ArrayList<SpanQuery> clausesList = new ArrayList<SpanQuery>();
		TokenStream tokens = this.analyzer.tokenStream(field, new StringReader(queryString));
		tokens.reset();

		while (tokens.incrementToken()) {
			String word = tokens.getAttribute(CharTermAttribute.class).toString();
			Term term = new Term(field, word);
			clausesList.add(new SpanTermQuery(term));
		}

		SpanQuery[] clauses = clausesList.toArray(new SpanQuery[clausesList.size()]);

		SpanNearQuery spannearQuery = new SpanNearQuery(clauses, 5, true);
		spannearQuery.setBoost(boost);
		return spannearQuery;    
	}

	private ResultSet doPagingSearch(Query query, int page, int maxPerPage) throws IOException {

		// Do the search
		TopDocs results = searcher.search(query, (page * maxPerPage) + maxPerPage);
		ScoreDoc[] hits = results.scoreDocs;

		int start = page * maxPerPage; // first page is page 0
		int end = Math.min((page + 1) * maxPerPage, results.totalHits);

		ArrayList<String> urls = new ArrayList<String>();	
		ArrayList<Integer> ids = new ArrayList<Integer>();	
		for (int i = start; i < end; i++) {
			// Results are in docIds, find the indexed document
			Document doc = searcher.doc(hits[i].doc);
			int id = hits[i].doc;
			// Save the URL of the document
			String url = doc.get("url");

			urls.add(url);
			ids.add(id);
		}

		return new ResultSet(urls, ids, results.totalHits);
	}

	public  String getHighlights(String url, String queryString, int id, String contentText) throws IOException, InvalidTokenOffsetsException, ParseException{
		StringBuilder stringBuilder = new StringBuilder();
		SimpleHTMLFormatter htmlFormatter = new SimpleHTMLFormatter();
		Query query = getFieldQuery(queryString, "content" , 1.0f);

		Highlighter highlighter = new Highlighter(htmlFormatter, new QueryScorer(query));

		TokenStream tokenStream = TokenSources.getAnyTokenStream(searcher.getIndexReader(), id, "content", analyzer);
		TextFragment[] frag = highlighter.getBestTextFragments(tokenStream, contentText, false, 4);

		for (int j = 0; j < frag.length; j++) {
			if ((frag[j] != null) && (frag[j].getScore() > 0)) {
				stringBuilder.append((frag[j].toString()));
				stringBuilder.append("...");
				stringBuilder.append("\n");
			}
		}

		return((stringBuilder.toString()));

	}


	public void close(){
		if (reader != null) {
			try {
				reader.close();
				analyzer.close();
			}
			catch (IOException e) {
				e.printStackTrace();
			}
		}
	}



}
